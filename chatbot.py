import os
import json
import faiss
import streamlit as st
from typing import List, Dict, Any, Tuple
from PyPDF2 import PdfReader
from sentence_transformers import SentenceTransformer
import google.genai as genai
from dotenv import load_dotenv

# ======================
# C·∫§U H√åNH
# ======================
load_dotenv()
API_KEY = os.getenv("GEMINI_API_KEY")
JSON_FILE = "so_tay_sinh_vien_k65.json"
PDF_FILE = "so_tay_sinh_vien_k65.pdf"
EMBED_MODEL = "keepitreal/vietnamese-sbert"
GEMINI_MODEL = "gemini-1.5-flash"

# ======================
# H√ÄM ƒê·ªåC PDF
# ======================
def read_pdf_pages(pdf_path: str, page_numbers: List[int]) -> Dict[int, str]:
    content_map = {}
    try:
        reader = PdfReader(pdf_path)
        for p in page_numbers:
            if 1 <= p <= len(reader.pages):
                page = reader.pages[p-1]
                text = page.extract_text() or ""
                content_map[p] = text.strip()
            else:
                content_map[p] = "[‚ö†Ô∏è Kh√¥ng t·ªìn t·∫°i trang n√†y trong PDF]"
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc PDF: {e}")
    return content_map

# ======================
# H√ÄM X√ÇY FAISS INDEX
# ======================
def load_documents(json_file: str) -> List[Dict[str, Any]]:
    with open(json_file, "r", encoding="utf-8") as f:
        return json.load(f)

def build_faiss_index(documents: List[Dict[str, Any]], model) -> Tuple[faiss.IndexFlatL2, List[Dict[str, Any]]]:
    texts = [doc["content"] for doc in documents]
    embeddings = model.encode(texts, convert_to_numpy=True)
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(embeddings)
    return index, documents

def retrieve_top_k(query: str, index, documents, model, k=3) -> List[Tuple[Dict[str, Any], float]]:
    query_emb = model.encode([query], convert_to_numpy=True)
    D, I = index.search(query_emb, k)
    return [(documents[i], float(D[0][j])) for j, i in enumerate(I[0])]

# ======================
# PROMPT
# ======================
def build_prompt(question, documents: List[Tuple[Dict[str, Any], float]]):
    page_nums = [doc_meta['page'] for doc_meta, _ in documents]
    pdf_texts = read_pdf_pages(PDF_FILE, page_nums)

    context_parts = []
    for doc_meta, score in documents:
        page_num = doc_meta['page']
        content = pdf_texts.get(page_num, "[‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y n·ªôi dung]")
        context_parts.append(f"N·ªôi dung trang {page_num}:\n{content}")
        
    context = "\n\n".join(context_parts)
    
    prompt = f"""
B·∫°n l√† m·ªôt tr·ª£ l√Ω ·∫£o. T√¥i s·∫Ω ƒë∆∞a cho b·∫°n m·ªôt c√¢u h·ªèi v√† m·ªôt s·ªë ƒëo·∫°n n·ªôi dung t·ª´ file PDF.
H√£y tr·∫£ l·ªùi NG·∫ÆN G·ªåN, TR·ª∞C TI·∫æP v√† ch·ªâ d·ª±a tr√™n n·ªôi dung ƒë√≥.
N·∫øu kh√¥ng ƒë·ªß th√¥ng tin, h√£y n√≥i r√µ "ch∆∞a ƒë·ªß d·ªØ li·ªáu".
N·∫øu KH√îNG t√¨m th·∫•y, tr·∫£ l·ªùi "Kh√¥ng t√¨m th·∫•y trong t√†i li·ªáu".

C√¢u h·ªèi: {question}

C√°c ƒëo·∫°n t√†i li·ªáu t·ª´ PDF:
{context}

C√¢u tr·∫£ l·ªùi:
"""
    return prompt

# ======================
# APP STREAMLIT
# ======================
def main():
    st.title("üìò Chatbot RAG v·ªõi PDF + JSON + Gemini (Chat mode)")

    if not API_KEY:
        st.error("‚ö†Ô∏è Ch∆∞a t√¨m th·∫•y GEMINI_API_KEY trong file .env")
        return

    # Init session_state
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Load model + d·ªØ li·ªáu 1 l·∫ßn
    if "index" not in st.session_state:
        with st.spinner("ƒêang load d·ªØ li·ªáu..."):
            model = SentenceTransformer(EMBED_MODEL)
            documents = load_documents(JSON_FILE)
            index, docs = build_faiss_index(documents, model)
            st.session_state.model = model
            st.session_state.index = index
            st.session_state.docs = docs

    # Hi·ªÉn th·ªã h·ªôi tho·∫°i
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # √î chat input
    if question := st.chat_input("Nh·∫≠p c√¢u h·ªèi..."):
        # L∆∞u user message
        st.session_state.messages.append({"role": "user", "content": question})
        with st.chat_message("user"):
            st.markdown(question)

        # Retrieve
        retrieved_docs = retrieve_top_k(question, st.session_state.index, st.session_state.docs, st.session_state.model, k=3)

        # Build prompt
        prompt = build_prompt(question, retrieved_docs)

        # G·ªçi Gemini
        client = genai.Client(api_key=API_KEY)
        response = client.models.generate_content(
            model=GEMINI_MODEL,
            contents=prompt
        )
        answer = response.text

        # L∆∞u assistant message
        st.session_state.messages.append({"role": "assistant", "content": answer})
        with st.chat_message("assistant"):
            st.markdown(answer)

        # Debug
        with st.expander("üìÑ Debug - Top t√†i li·ªáu l·∫•y ra"):
            for doc, score in retrieved_docs:
                st.markdown(f"**Trang {doc['page']}** (score={score:.4f})")

if __name__ == "__main__":
    main()
